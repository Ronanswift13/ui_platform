#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è·¨å¹³å°è®­ç»ƒå™¨æ ¸å¿ƒæ¨¡å—
===================

æ”¯æŒ:
- Mac Mç³»åˆ— (MPSåŠ é€Ÿ)
- Windows (CUDA)
- CPUå›é€€

ä½œè€…: ç ´å¤œç»˜æ˜å›¢é˜Ÿ
"""

import os
import sys
import json
import time
import platform
import logging
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Any, Callable
from datetime import datetime

import numpy as np

# PyTorchå¯¼å…¥
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import DataLoader
    from torch.cuda.amp import autocast, GradScaler
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    F = None

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


# =============================================================================
# å¹³å°æ£€æµ‹
# =============================================================================
@dataclass
class PlatformInfo:
    """å¹³å°ä¿¡æ¯"""
    system: str              # Darwin, Windows, Linux
    machine: str             # arm64, x86_64
    device: str              # mps, cuda, cpu
    device_name: str         # è®¾å¤‡åç§°
    memory_gb: float         # å¯ç”¨å†…å­˜
    is_apple_silicon: bool   # æ˜¯å¦ä¸ºApple Silicon
    cuda_available: bool     # CUDAæ˜¯å¦å¯ç”¨
    mps_available: bool      # MPSæ˜¯å¦å¯ç”¨
    recommended_batch_size: int
    recommended_precision: str  # float32, float16


def detect_platform() -> PlatformInfo:
    """æ£€æµ‹å½“å‰è¿è¡Œå¹³å°"""
    system = platform.system()
    machine = platform.machine()
    
    # æ£€æµ‹Apple Silicon
    is_apple_silicon = (system == "Darwin" and machine == "arm64")
    
    # æ£€æµ‹CUDA
    cuda_available = False
    cuda_device_name = ""
    if TORCH_AVAILABLE:
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            cuda_device_name = torch.cuda.get_device_name(0)
    
    # æ£€æµ‹MPS
    mps_available = False
    if TORCH_AVAILABLE and hasattr(torch.backends, 'mps'):
        mps_available = torch.backends.mps.is_available()
    
    # ç¡®å®šæœ€ä½³è®¾å¤‡
    if mps_available:
        device = "mps"
        device_name = f"Apple Silicon ({machine})"
        recommended_batch_size = 16
        recommended_precision = "float32"  # MPSå¯¹FP16æ”¯æŒæœ‰é™
    elif cuda_available:
        device = "cuda"
        device_name = cuda_device_name
        recommended_batch_size = 32
        recommended_precision = "float16"
    else:
        device = "cpu"
        device_name = f"CPU ({machine})"
        recommended_batch_size = 8
        recommended_precision = "float32"
    
    # è·å–å†…å­˜ä¿¡æ¯
    try:
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
    except ImportError:
        memory_gb = 24.0 if is_apple_silicon else 16.0  # ä¼°è®¡å€¼
    
    return PlatformInfo(
        system=system,
        machine=machine,
        device=device,
        device_name=device_name,
        memory_gb=memory_gb,
        is_apple_silicon=is_apple_silicon,
        cuda_available=cuda_available,
        mps_available=mps_available,
        recommended_batch_size=recommended_batch_size,
        recommended_precision=recommended_precision
    )


def get_device(prefer: str = "auto") -> torch.device:
    """
    è·å–PyTorchè®¾å¤‡
    
    Args:
        prefer: åå¥½è®¾å¤‡ ("auto", "mps", "cuda", "cpu")
    
    Returns:
        torch.device
    """
    if not TORCH_AVAILABLE:
        raise RuntimeError("PyTorchæœªå®‰è£…")
    
    if prefer == "auto":
        platform_info = detect_platform()
        prefer = platform_info.device
    
    if prefer == "mps" and torch.backends.mps.is_available():
        logger.info("âœ… ä½¿ç”¨ Apple Silicon MPS åŠ é€Ÿ")
        return torch.device("mps")
    elif prefer == "cuda" and torch.cuda.is_available():
        logger.info(f"âœ… ä½¿ç”¨ NVIDIA CUDA: {torch.cuda.get_device_name(0)}")
        return torch.device("cuda")
    else:
        logger.info("âš ï¸ ä½¿ç”¨ CPU è®­ç»ƒ")
        return torch.device("cpu")


# =============================================================================
# è®­ç»ƒé…ç½®
# =============================================================================
@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    # åŸºç¡€é…ç½®
    model_name: str = "default"
    epochs: int = 50
    batch_size: int = 16
    learning_rate: float = 1e-4
    weight_decay: float = 1e-5
    
    # ä¼˜åŒ–å™¨é…ç½®
    optimizer: str = "adamw"  # adam, adamw, sgd
    scheduler: str = "cosine"  # cosine, step, plateau
    warmup_epochs: int = 5
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp: bool = False  # è‡ªåŠ¨æ··åˆç²¾åº¦
    
    # æ•°æ®å¢å¼º
    augmentation: bool = True
    
    # æ—©åœ
    early_stopping: bool = True
    patience: int = 10
    
    # æ£€æŸ¥ç‚¹
    save_dir: str = "checkpoints"
    save_best_only: bool = True
    save_frequency: int = 5
    
    # æ—¥å¿—
    log_frequency: int = 10
    use_tensorboard: bool = True
    use_wandb: bool = False
    
    # éªŒè¯
    val_frequency: int = 1
    
    # è®¾å¤‡
    device: str = "auto"
    num_workers: int = 4


# =============================================================================
# è®­ç»ƒå›è°ƒ
# =============================================================================
class TrainingCallback:
    """è®­ç»ƒå›è°ƒåŸºç±»"""
    
    def on_train_begin(self, trainer):
        pass
    
    def on_train_end(self, trainer):
        pass
    
    def on_epoch_begin(self, trainer, epoch):
        pass
    
    def on_epoch_end(self, trainer, epoch, logs):
        pass
    
    def on_batch_begin(self, trainer, batch_idx):
        pass
    
    def on_batch_end(self, trainer, batch_idx, logs):
        pass


class EarlyStopping(TrainingCallback):
    """æ—©åœå›è°ƒ"""
    
    def __init__(self, patience: int = 10, min_delta: float = 1e-4, 
                 monitor: str = "val_loss", mode: str = "min"):
        self.patience = patience
        self.min_delta = min_delta
        self.monitor = monitor
        self.mode = mode
        self.counter = 0
        self.best_value = None
        self.should_stop = False
    
    def on_epoch_end(self, trainer, epoch, logs):
        current = logs.get(self.monitor)
        if current is None:
            return
        
        if self.best_value is None:
            self.best_value = current
        elif self._is_improvement(current):
            self.best_value = current
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.should_stop = True
                logger.info(f"æ—©åœè§¦å‘: {self.patience}è½®æ— æ”¹å–„")
    
    def _is_improvement(self, current):
        if self.mode == "min":
            return current < self.best_value - self.min_delta
        else:
            return current > self.best_value + self.min_delta


class ModelCheckpoint(TrainingCallback):
    """æ¨¡å‹æ£€æŸ¥ç‚¹å›è°ƒ"""
    
    def __init__(self, save_dir: str, monitor: str = "val_loss",
                 mode: str = "min", save_best_only: bool = True):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(parents=True, exist_ok=True)
        self.monitor = monitor
        self.mode = mode
        self.save_best_only = save_best_only
        self.best_value = None
    
    def on_epoch_end(self, trainer, epoch, logs):
        current = logs.get(self.monitor)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜
        should_save = False
        if not self.save_best_only:
            should_save = True
        elif current is not None:
            if self.best_value is None:
                should_save = True
                self.best_value = current
            elif self._is_improvement(current):
                should_save = True
                self.best_value = current
        
        if should_save:
            self._save_checkpoint(trainer, epoch, logs)
    
    def _is_improvement(self, current):
        if self.mode == "min":
            return current < self.best_value
        else:
            return current > self.best_value
    
    def _save_checkpoint(self, trainer, epoch, logs):
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': trainer.model.state_dict(),
            'optimizer_state_dict': trainer.optimizer.state_dict(),
            'logs': logs,
            'config': trainer.config.__dict__,
            'platform': detect_platform().__dict__,
            'timestamp': datetime.now().isoformat()
        }
        
        if trainer.scheduler is not None:
            checkpoint['scheduler_state_dict'] = trainer.scheduler.state_dict()
        
        save_path = self.save_dir / f"{trainer.config.model_name}_best.pth"
        torch.save(checkpoint, save_path)
        logger.info(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {save_path}")


# =============================================================================
# è·¨å¹³å°è®­ç»ƒå™¨
# =============================================================================
class CrossPlatformTrainer:
    """
    è·¨å¹³å°æ¨¡å‹è®­ç»ƒå™¨
    
    æ”¯æŒMac MPSå’ŒWindows CUDAï¼Œè‡ªåŠ¨å¤„ç†è®¾å¤‡å·®å¼‚
    """
    
    def __init__(self, model: nn.Module, config: TrainingConfig = None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: PyTorchæ¨¡å‹
            config: è®­ç»ƒé…ç½®
        """
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorchæœªå®‰è£…")
        
        self.config = config or TrainingConfig()
        self.platform_info = detect_platform()
        
        # è®¾å¤‡è®¾ç½®
        self.device = get_device(self.config.device)
        self.model = model.to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = self._create_optimizer()
        self.scheduler = self._create_scheduler()
        
        # æ··åˆç²¾åº¦
        self.scaler = None
        if self.config.use_amp and self.device.type == "cuda":
            self.scaler = GradScaler()
        
        # å›è°ƒ
        self.callbacks: List[TrainingCallback] = []
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.global_step = 0
        self.best_val_loss = float('inf')
        self.history = {'train_loss': [], 'val_loss': [], 'val_acc': []}
        
        # æ—¥å¿—
        self._setup_logging()
    
    def _create_optimizer(self) -> optim.Optimizer:
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        params = self.model.parameters()
        
        if self.config.optimizer == "adam":
            return optim.Adam(
                params, 
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay
            )
        elif self.config.optimizer == "adamw":
            return optim.AdamW(
                params,
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay
            )
        elif self.config.optimizer == "sgd":
            return optim.SGD(
                params,
                lr=self.config.learning_rate,
                momentum=0.9,
                weight_decay=self.config.weight_decay
            )
        else:
            raise ValueError(f"æœªçŸ¥ä¼˜åŒ–å™¨: {self.config.optimizer}")
    
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if self.config.scheduler == "cosine":
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.epochs
            )
        elif self.config.scheduler == "step":
            return optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=self.config.epochs // 3,
                gamma=0.1
            )
        elif self.config.scheduler == "plateau":
            return optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer,
                mode='min',
                factor=0.5,
                patience=5
            )
        else:
            return None
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = Path(self.config.save_dir) / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # TensorBoard
        if self.config.use_tensorboard:
            try:
                from torch.utils.tensorboard import SummaryWriter
                self.writer = SummaryWriter(log_dir / "tensorboard")
            except ImportError:
                self.writer = None
                logger.warning("TensorBoardæœªå®‰è£…")
        else:
            self.writer = None
    
    def add_callback(self, callback: TrainingCallback):
        """æ·»åŠ å›è°ƒ"""
        self.callbacks.append(callback)
    
    def _run_callbacks(self, event: str, **kwargs):
        """æ‰§è¡Œå›è°ƒ"""
        for callback in self.callbacks:
            method = getattr(callback, event, None)
            if method:
                method(self, **kwargs)
    
    def train(self, train_loader: DataLoader, 
              val_loader: DataLoader = None,
              criterion: nn.Module = None) -> Dict[str, List]:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            criterion: æŸå¤±å‡½æ•°
        
        Returns:
            è®­ç»ƒå†å²
        """
        if criterion is None:
            criterion = nn.CrossEntropyLoss()
        
        # è®¾ç½®é»˜è®¤å›è°ƒ
        if self.config.early_stopping:
            self.add_callback(EarlyStopping(patience=self.config.patience))
        
        self.add_callback(ModelCheckpoint(
            save_dir=self.config.save_dir,
            save_best_only=self.config.save_best_only
        ))
        
        # æ‰“å°è®­ç»ƒä¿¡æ¯
        self._print_training_info()
        
        # å¼€å§‹è®­ç»ƒ
        self._run_callbacks('on_train_begin')
        
        for epoch in range(self.config.epochs):
            self.current_epoch = epoch
            self._run_callbacks('on_epoch_begin', epoch=epoch)
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss = self._train_epoch(train_loader, criterion)
            
            # éªŒè¯
            val_loss, val_acc = 0.0, 0.0
            if val_loader is not None and (epoch + 1) % self.config.val_frequency == 0:
                val_loss, val_acc = self._validate(val_loader, criterion)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler is not None:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_loss)
                else:
                    self.scheduler.step()
            
            # è®°å½•å†å²
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            self.history['val_acc'].append(val_acc)
            
            # æ—¥å¿—
            logs = {
                'train_loss': train_loss,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'lr': self.optimizer.param_groups[0]['lr']
            }
            
            self._log_epoch(epoch, logs)
            self._run_callbacks('on_epoch_end', epoch=epoch, logs=logs)
            
            # æ£€æŸ¥æ—©åœ
            for callback in self.callbacks:
                if isinstance(callback, EarlyStopping) and callback.should_stop:
                    logger.info("æ—©åœè§¦å‘ï¼Œè®­ç»ƒç»“æŸ")
                    break
            else:
                continue
            break
        
        self._run_callbacks('on_train_end')
        
        return self.history
    
    def _train_epoch(self, train_loader: DataLoader,
                     criterion: nn.Module) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = len(train_loader)

        for batch_idx, batch in enumerate(train_loader):
            self._run_callbacks('on_batch_begin', batch_idx=batch_idx)

            # å¤„ç†ä¸åŒæ ¼å¼çš„batch
            if isinstance(batch, (tuple, list)):
                if len(batch) == 2:
                    data, target = batch
                else:
                    data, target = batch[0], batch[1]
            else:
                data, target = batch['image'], batch['label']

            data = data.to(self.device)

            # å¤„ç†ç›®æ ‡ - æ£€æµ‹ä»»åŠ¡targetæ˜¯åˆ—è¡¨ï¼Œåˆ†ç±»ä»»åŠ¡æ˜¯tensor
            if isinstance(target, list):
                # ç›®æ ‡æ£€æµ‹: targetæ˜¯dictåˆ—è¡¨
                target = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                          for k, v in t.items()} for t in target]
            elif isinstance(target, torch.Tensor):
                target = target.to(self.device)

            self.optimizer.zero_grad()

            # æ··åˆç²¾åº¦è®­ç»ƒ
            if self.scaler is not None:
                with autocast():
                    output = self.model(data)
                    loss = self._compute_loss(output, target, criterion)

                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                output = self.model(data)
                loss = self._compute_loss(output, target, criterion)
                loss.backward()
                self.optimizer.step()

            total_loss += loss.item()
            self.global_step += 1

            # æ—¥å¿—
            if (batch_idx + 1) % self.config.log_frequency == 0:
                logger.info(
                    f"Epoch [{self.current_epoch+1}/{self.config.epochs}] "
                    f"Batch [{batch_idx+1}/{num_batches}] "
                    f"Loss: {loss.item():.4f}"
                )

            self._run_callbacks('on_batch_end', batch_idx=batch_idx,
                              logs={'loss': loss.item()})

        return total_loss / num_batches

    def _compute_loss(self, output, target, criterion):
        """è®¡ç®—æŸå¤±ï¼Œå¤„ç†ä¸åŒæ¨¡å‹è¾“å‡ºæ ¼å¼"""
        # æ£€æµ‹æ¨¡å‹è¾“å‡ºæ˜¯åˆ—è¡¨
        if isinstance(output, list):
            if len(output) > 0 and isinstance(output[0], dict):
                # YOLOv8é£æ ¼è¾“å‡º: [{'cls': ..., 'reg': ...}, ...]
                # ç®€åŒ–æŸå¤±: ä½¿ç”¨åˆ†ç±»æŸå¤±ä½œä¸ºä»£ç†
                total_loss = torch.tensor(0.0, device=self.device)
                for out in output:
                    if 'cls' in out:
                        cls_out = out['cls']  # [B, num_classes, num_anchors]
                        # ä½¿ç”¨ç®€åŒ–çš„åˆ†ç±»æŸå¤±
                        cls_out = cls_out.permute(0, 2, 1)  # [B, num_anchors, num_classes]
                        B, A, C = cls_out.shape
                        # åˆ›å»ºä¼ªæ ‡ç­¾ (å®é™…è®­ç»ƒéœ€è¦æ ¹æ®targetç”Ÿæˆ)
                        pseudo_labels = torch.zeros(B, A, dtype=torch.long, device=self.device)
                        total_loss += F.cross_entropy(cls_out.reshape(-1, C), pseudo_labels.reshape(-1))
                return total_loss / len(output) if output else torch.tensor(0.0, device=self.device)
            else:
                # å…¶ä»–åˆ—è¡¨æ ¼å¼
                return criterion(output[0], target)
        # å­—å…¸æ ¼å¼è¾“å‡º (RT-DETR)
        elif isinstance(output, dict):
            if 'pred_logits' in output:
                pred_logits = output['pred_logits']
                B, Q, C = pred_logits.shape
                # ç®€åŒ–: å¯¹æ‰€æœ‰queryä½¿ç”¨èƒŒæ™¯ç±»æ ‡ç­¾
                pseudo_labels = torch.full((B, Q), C-1, dtype=torch.long, device=self.device)
                return F.cross_entropy(pred_logits.reshape(-1, C), pseudo_labels.reshape(-1))
            return criterion(list(output.values())[0], target)
        # æ ‡å‡†tensorè¾“å‡º
        else:
            return criterion(output, target)
    
    def _validate(self, val_loader: DataLoader,
                  criterion: nn.Module) -> Tuple[float, float]:
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0

        with torch.no_grad():
            for batch in val_loader:
                if isinstance(batch, (tuple, list)):
                    data, target = batch[0], batch[1]
                else:
                    data, target = batch['image'], batch['label']

                data = data.to(self.device)

                # å¤„ç†ç›®æ ‡ - æ£€æµ‹ä»»åŠ¡targetæ˜¯åˆ—è¡¨ï¼Œåˆ†ç±»ä»»åŠ¡æ˜¯tensor
                if isinstance(target, list):
                    target = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                              for k, v in t.items()} for t in target]
                elif isinstance(target, torch.Tensor):
                    target = target.to(self.device)

                output = self.model(data)
                loss = self._compute_loss(output, target, criterion)

                total_loss += loss.item()

                # è®¡ç®—å‡†ç¡®ç‡ (ä»…å¯¹åˆ†ç±»ä»»åŠ¡)
                if isinstance(output, torch.Tensor) and output.dim() > 1 and isinstance(target, torch.Tensor):
                    _, predicted = output.max(1)
                    total += target.size(0)
                    correct += predicted.eq(target).sum().item()

        avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0.0
        accuracy = correct / total if total > 0 else 0.0

        return avg_loss, accuracy
    
    def _log_epoch(self, epoch: int, logs: Dict):
        """è®°å½•epochæ—¥å¿—"""
        logger.info(
            f"Epoch {epoch+1}/{self.config.epochs} | "
            f"Train Loss: {logs['train_loss']:.4f} | "
            f"Val Loss: {logs['val_loss']:.4f} | "
            f"Val Acc: {logs['val_acc']:.4f} | "
            f"LR: {logs['lr']:.6f}"
        )
        
        # TensorBoard
        if self.writer is not None:
            self.writer.add_scalar('Loss/train', logs['train_loss'], epoch)
            self.writer.add_scalar('Loss/val', logs['val_loss'], epoch)
            self.writer.add_scalar('Accuracy/val', logs['val_acc'], epoch)
            self.writer.add_scalar('Learning_rate', logs['lr'], epoch)
    
    def _print_training_info(self):
        """æ‰“å°è®­ç»ƒä¿¡æ¯"""
        logger.info("=" * 60)
        logger.info("è®­ç»ƒé…ç½®")
        logger.info("=" * 60)
        logger.info(f"æ¨¡å‹åç§°: {self.config.model_name}")
        logger.info(f"è®¾å¤‡: {self.device} ({self.platform_info.device_name})")
        logger.info(f"å¹³å°: {self.platform_info.system} ({self.platform_info.machine})")
        logger.info(f"Epochs: {self.config.epochs}")
        logger.info(f"Batch Size: {self.config.batch_size}")
        logger.info(f"Learning Rate: {self.config.learning_rate}")
        logger.info(f"ä¼˜åŒ–å™¨: {self.config.optimizer}")
        logger.info(f"è°ƒåº¦å™¨: {self.config.scheduler}")
        logger.info(f"æ··åˆç²¾åº¦: {self.config.use_amp}")
        logger.info("=" * 60)
    
    def save_checkpoint(self, path: str):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'history': self.history,
            'config': self.config.__dict__,
            'platform': self.platform_info.__dict__
        }
        
        if self.scheduler is not None:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        torch.save(checkpoint, path)
        logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {path}")
    
    def load_checkpoint(self, path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if 'scheduler_state_dict' in checkpoint and self.scheduler is not None:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.current_epoch = checkpoint.get('epoch', 0)
        self.history = checkpoint.get('history', self.history)
        
        logger.info(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {path}")


# =============================================================================
# è®­ç»ƒæµæ°´çº¿
# =============================================================================
class TrainingPipeline:
    """
    å®Œæ•´è®­ç»ƒæµæ°´çº¿
    
    ç®¡ç†æ‰€æœ‰æ’ä»¶æ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œå¯¼å‡º
    """
    
    # æ’ä»¶æ¨¡å‹æ˜ å°„
    PLUGIN_MODELS = {
        "transformer": [
            {"name": "defect_yolov8n", "type": "detection", "input_size": (640, 640)},
            {"name": "oil_unet", "type": "segmentation", "input_size": (512, 512)},
            {"name": "silica_cnn", "type": "classification", "input_size": (224, 224)},
            {"name": "thermal_anomaly", "type": "classification", "input_size": (224, 224)},
        ],
        "switch": [
            {"name": "switch_yolov8s", "type": "detection", "input_size": (640, 640)},
            {"name": "indicator_ocr", "type": "ocr", "input_size": (32, 128)},
        ],
        "busbar": [
            {"name": "busbar_yolov8m", "type": "detection", "input_size": (1280, 1280)},
            {"name": "noise_classifier", "type": "classification", "input_size": (128, 128)},
        ],
        "capacitor": [
            {"name": "capacitor_yolov8", "type": "detection", "input_size": (640, 640)},
            {"name": "rtdetr_intrusion", "type": "detection", "input_size": (640, 640)},
        ],
        "meter": [
            {"name": "hrnet_keypoint", "type": "keypoint", "input_size": (256, 256)},
            {"name": "crnn_ocr", "type": "ocr", "input_size": (32, 128)},
            {"name": "meter_classifier", "type": "classification", "input_size": (224, 224)},
        ],
    }
    
    def __init__(self, base_dir: str = ".", config: Dict = None):
        """
        åˆå§‹åŒ–æµæ°´çº¿
        
        Args:
            base_dir: é¡¹ç›®æ ¹ç›®å½•
            config: å…¨å±€é…ç½®
        """
        self.base_dir = Path(base_dir)
        self.config = config or {}
        self.platform_info = detect_platform()
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self._create_directories()
        
        # è®­ç»ƒçŠ¶æ€
        self.trained_models = {}
        
        logger.info(f"è®­ç»ƒæµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"å¹³å°: {self.platform_info.system} ({self.platform_info.device})")
    
    def _create_directories(self):
        """åˆ›å»ºç›®å½•ç»“æ„"""
        dirs = [
            "models/transformer",
            "models/switch", 
            "models/busbar",
            "models/capacitor",
            "models/meter",
            "models/common",
            "checkpoints",
            "logs",
            "data/raw",
            "data/processed",
            "exports/onnx",
        ]
        
        for d in dirs:
            (self.base_dir / d).mkdir(parents=True, exist_ok=True)
    
    def train_plugin(self, plugin_name: str, 
                     model_name: str = None,
                     epochs: int = 50,
                     batch_size: int = None,
                     data_dir: str = None,
                     pretrained: bool = True) -> Dict:
        """
        è®­ç»ƒå•ä¸ªæ’ä»¶æ¨¡å‹
        
        Args:
            plugin_name: æ’ä»¶åç§° (transformer, switch, busbar, capacitor, meter)
            model_name: æ¨¡å‹åç§°ï¼Œå¦‚ä¸æŒ‡å®šåˆ™è®­ç»ƒè¯¥æ’ä»¶æ‰€æœ‰æ¨¡å‹
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹å¤§å°
            data_dir: æ•°æ®ç›®å½•
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        
        Returns:
            è®­ç»ƒç»“æœ
        """
        if plugin_name not in self.PLUGIN_MODELS:
            raise ValueError(f"æœªçŸ¥æ’ä»¶: {plugin_name}")
        
        models = self.PLUGIN_MODELS[plugin_name]
        if model_name:
            models = [m for m in models if m['name'] == model_name]
            if not models:
                raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")
        
        results = {}
        
        for model_info in models:
            logger.info(f"\n{'='*60}")
            logger.info(f"è®­ç»ƒæ¨¡å‹: {plugin_name}/{model_info['name']}")
            logger.info(f"{'='*60}")
            
            try:
                result = self._train_single_model(
                    plugin_name=plugin_name,
                    model_info=model_info,
                    epochs=epochs,
                    batch_size=batch_size or self.platform_info.recommended_batch_size,
                    data_dir=data_dir,
                    pretrained=pretrained
                )
                results[model_info['name']] = result
                self.trained_models[f"{plugin_name}/{model_info['name']}"] = result
                
            except Exception as e:
                logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
                results[model_info['name']] = {"status": "failed", "error": str(e)}
        
        return results
    
    def _train_single_model(self, plugin_name: str, model_info: Dict,
                           epochs: int, batch_size: int,
                           data_dir: str, pretrained: bool) -> Dict:
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        from .models import create_model
        from .datasets import create_dataloader
        
        model_type = model_info['type']
        model_name = model_info['name']
        input_size = model_info['input_size']
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(
            model_type=model_type,
            model_name=model_name,
            input_size=input_size,
            pretrained=pretrained,
            plugin_name=plugin_name
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader = create_dataloader(
            plugin_name=plugin_name,
            model_type=model_type,
            data_dir=data_dir or str(self.base_dir / "data"),
            batch_size=batch_size,
            input_size=input_size
        )
        
        # è®­ç»ƒé…ç½®
        config = TrainingConfig(
            model_name=f"{plugin_name}_{model_name}",
            epochs=epochs,
            batch_size=batch_size,
            save_dir=str(self.base_dir / "checkpoints" / plugin_name),
            use_amp=(self.platform_info.device == "cuda")
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = CrossPlatformTrainer(model, config)
        
        # é€‰æ‹©æŸå¤±å‡½æ•°
        criterion = self._get_criterion(model_type)
        
        # è®­ç»ƒ
        history = trainer.train(train_loader, val_loader, criterion)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        save_path = self.base_dir / "checkpoints" / plugin_name / f"{model_name}_final.pth"
        trainer.save_checkpoint(str(save_path))
        
        return {
            "status": "success",
            "model_path": str(save_path),
            "history": history,
            "best_val_acc": max(history.get('val_acc', [0])),
            "final_train_loss": history['train_loss'][-1] if history['train_loss'] else None
        }
    
    def _get_criterion(self, model_type: str) -> nn.Module:
        """è·å–æŸå¤±å‡½æ•°"""
        if model_type == "detection":
            # YOLOä½¿ç”¨è‡ªå®šä¹‰æŸå¤±
            return nn.CrossEntropyLoss()  # ç®€åŒ–ï¼Œå®é™…ä½¿ç”¨YOLOæŸå¤±
        elif model_type == "segmentation":
            return nn.BCEWithLogitsLoss()
        elif model_type == "classification":
            return nn.CrossEntropyLoss()
        elif model_type == "keypoint":
            return nn.MSELoss()
        elif model_type == "ocr":
            return nn.CTCLoss(blank=0, zero_infinity=True)
        else:
            return nn.CrossEntropyLoss()
    
    def train_all(self, epochs: int = 50, 
                  plugins: List[str] = None) -> Dict:
        """
        è®­ç»ƒæ‰€æœ‰æ’ä»¶æ¨¡å‹
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            plugins: è¦è®­ç»ƒçš„æ’ä»¶åˆ—è¡¨ï¼Œé»˜è®¤å…¨éƒ¨
        
        Returns:
            æ‰€æœ‰è®­ç»ƒç»“æœ
        """
        plugins = plugins or list(self.PLUGIN_MODELS.keys())
        
        all_results = {}
        
        for plugin in plugins:
            logger.info(f"\n\n{'#'*60}")
            logger.info(f"# å¼€å§‹è®­ç»ƒæ’ä»¶: {plugin}")
            logger.info(f"{'#'*60}")
            
            results = self.train_plugin(plugin, epochs=epochs)
            all_results[plugin] = results
        
        # ä¿å­˜è®­ç»ƒæ‘˜è¦
        self._save_training_summary(all_results)
        
        return all_results
    
    def export_onnx(self, plugin_name: str, model_name: str,
                    checkpoint_path: str = None,
                    opset_version: int = 17) -> str:
        """
        å¯¼å‡ºæ¨¡å‹ä¸ºONNXæ ¼å¼
        
        Args:
            plugin_name: æ’ä»¶åç§°
            model_name: æ¨¡å‹åç§°
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
            opset_version: ONNX opsetç‰ˆæœ¬
        
        Returns:
            ONNXæ–‡ä»¶è·¯å¾„
        """
        from .exporters import ONNXExporter
        from .models import create_model
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        models = self.PLUGIN_MODELS.get(plugin_name, [])
        model_info = next((m for m in models if m['name'] == model_name), None)
        if not model_info:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {plugin_name}/{model_name}")
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(
            model_type=model_info['type'],
            model_name=model_name,
            input_size=model_info['input_size'],
            pretrained=False,
            plugin_name=plugin_name
        )
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        if checkpoint_path is None:
            checkpoint_path = self.base_dir / "checkpoints" / plugin_name / f"{model_name}_best.pth"
        
        if Path(checkpoint_path).exists():
            checkpoint = torch.load(checkpoint_path, map_location='cpu')
            model.load_state_dict(checkpoint['model_state_dict'])
        
        # å¯¼å‡ºONNX
        exporter = ONNXExporter(opset_version=opset_version)
        
        output_path = self.base_dir / "models" / plugin_name / f"{model_name}.onnx"
        
        exporter.export(
            model=model,
            input_shape=(3, *model_info['input_size']),
            save_path=str(output_path),
            dynamic_batch=True
        )
        
        return str(output_path)
    
    def export_all_onnx(self) -> Dict[str, str]:
        """å¯¼å‡ºæ‰€æœ‰æ¨¡å‹ä¸ºONNX"""
        exported = {}
        
        for plugin_name, models in self.PLUGIN_MODELS.items():
            for model_info in models:
                try:
                    onnx_path = self.export_onnx(plugin_name, model_info['name'])
                    exported[f"{plugin_name}/{model_info['name']}"] = onnx_path
                    logger.info(f"âœ… å¯¼å‡ºæˆåŠŸ: {onnx_path}")
                except Exception as e:
                    logger.error(f"âŒ å¯¼å‡ºå¤±è´¥ {plugin_name}/{model_info['name']}: {e}")
                    exported[f"{plugin_name}/{model_info['name']}"] = f"ERROR: {e}"
        
        return exported
    
    def _save_training_summary(self, results: Dict):
        """ä¿å­˜è®­ç»ƒæ‘˜è¦"""
        summary = {
            "timestamp": datetime.now().isoformat(),
            "platform": self.platform_info.__dict__,
            "results": results
        }
        
        summary_path = self.base_dir / "checkpoints" / "training_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"è®­ç»ƒæ‘˜è¦å·²ä¿å­˜: {summary_path}")


# =============================================================================
# ä¾¿æ·å‡½æ•°
# =============================================================================
def quick_train(plugin: str, model: str = None, epochs: int = 50, 
                data_dir: str = None) -> Dict:
    """
    å¿«é€Ÿè®­ç»ƒæ¨¡å‹
    
    Example:
        # è®­ç»ƒä¸»å˜ç¼ºé™·æ£€æµ‹æ¨¡å‹
        result = quick_train("transformer", "defect_yolov8n", epochs=50)
        
        # è®­ç»ƒæ‰€æœ‰è¡¨è®¡æ¨¡å‹
        result = quick_train("meter", epochs=30)
    """
    pipeline = TrainingPipeline()
    return pipeline.train_plugin(plugin, model, epochs=epochs, data_dir=data_dir)


def quick_export(plugin: str, model: str) -> str:
    """
    å¿«é€Ÿå¯¼å‡ºONNX
    
    Example:
        onnx_path = quick_export("transformer", "defect_yolov8n")
    """
    pipeline = TrainingPipeline()
    return pipeline.export_onnx(plugin, model)
